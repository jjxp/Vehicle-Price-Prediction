{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9564f8-ed3d-49ff-b6d3-1d191afc7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extract_vehicle_data(start = 1, end = 50, base_url = 'https://www.milanuncios.com/coches-de-segunda-mano/?pagina='):\n",
    "    '''\n",
    "    Connects to Milanuncios and extracts a list of predefined features from each vehicle listed.\n",
    "\n",
    "    Parameters:\n",
    "        start (int):The first page over which we want to start scrapping.\n",
    "        end (int):The last page on which we want to stop scrapping.\n",
    "        base_url (str):The base URL to which we want to connect.\n",
    "\n",
    "    Returns:\n",
    "        vehicle_list(list):List of dictionaries containing information about all the vehicles listed within the execution.\n",
    "    '''\n",
    "    try:\n",
    "        assert isinstance(start, int), 'The \"start\" parameter is not an integer.'\n",
    "        assert isinstance(end, int), 'The \"end\" parameter is not an integer.'\n",
    "        assert isinstance(base_url, str), 'The \"base_url\" parameter is not a string.'\n",
    "        assert start > 0, 'The \"start\" parameter has to be greater than 0.'\n",
    "        assert start < end, 'The \"end\" parameter has to be greater than the \"start\" parameter.'\n",
    "        assert re.match('https://www\\.milanuncios\\.com/.+pagina=$', base_url), 'The \"base_url\" parameter does not match the expected regex.'\n",
    "    except AssertionError as ae:\n",
    "        print(ae)\n",
    "        \n",
    "    # Create an instance of the Chrome web driver\n",
    "    browser = webdriver.Chrome()\n",
    "\n",
    "    vehicle_list = []\n",
    "    # Iterate over each page until specified in the range function\n",
    "    for page in range(start, end + 1):\n",
    "        # Form the real URL appending the string value of the current page over which we're iterating\n",
    "        browser.get(base_url + str(page))\n",
    "\n",
    "        # Wait a little for the website to load\n",
    "        time.sleep(1)\n",
    "\n",
    "        # If we're on the first page, dismiss the cookies pop-up\n",
    "        if page == start:\n",
    "            browser.find_element_by_css_selector('button.sui-AtomButton.sui-AtomButton--primary.sui-AtomButton--solid.sui-AtomButton--center').click()\n",
    "\n",
    "        # Calculate the height of the website\n",
    "        total_height = int(browser.execute_script(\"return document.body.scrollHeight\"))\n",
    "\n",
    "        # Slowly scroll down until you reach the bottom\n",
    "        for i in range(1, total_height, 50):\n",
    "            browser.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "\n",
    "        # Capture the DOM elements of our interest\n",
    "        post_elems = browser.find_elements_by_class_name(\"ma-AdCard-body\")\n",
    "\n",
    "        # Iterate over each of the elements that we're capturing\n",
    "        for post in post_elems:\n",
    "\n",
    "            # Sometimes you'll also capture ads. Skip them.\n",
    "            if 'OFERTA PATROCINADA' in post.find_element_by_xpath('..').text:\n",
    "                print('Skipping ad...')\n",
    "                continue\n",
    "\n",
    "            # Convert the captured data into BS4 format for simplified extractions\n",
    "            html = post.get_attribute('innerHTML')\n",
    "            soup = BeautifulSoup(html)\n",
    "\n",
    "            # Certain features are not listed in an structured format and we cannot access them directly\n",
    "            tags = [x.text for x in soup.find_all('span', {'class': 'ma-AdTag-label'})]\n",
    "\n",
    "            # Try to extract the associated features. In certain situations, some will miss. In this situation, we will skip the entire row.\n",
    "            # These are all very important for machine learning purpuses and it's rare to find a missing value, so it's preferable to skip it at this point.\n",
    "            try:\n",
    "                location = soup.find('a', {'class': 'ma-AdCard-subtitleLink'}).text.split(' en ')[1]\n",
    "                hp = next(x for x in tags if x.endswith('CV'))\n",
    "                mileage = next(x for x in tags if x.endswith('kms') or x.endswith('km'))\n",
    "                year = next(x for x in tags if x.isdigit())\n",
    "                transmission = next(x for x in tags if x in ['Manual', 'AutomÃ¡tico'])\n",
    "                doors = next(x for x in tags if x.endswith('puertas'))\n",
    "                price = soup.find('span', {'class': 'ma-AdPrice-value'}).text\n",
    "            except:\n",
    "                print('Found a problem when gathering information for: [', soup.find('h2').text, '] Skipping...')\n",
    "                continue\n",
    "\n",
    "            # Populate all the features in a dictionary\n",
    "            vehicle = {\n",
    "                'title': soup.find('h2').text,\n",
    "                'location': location,\n",
    "                'url': soup.find('a', {'class': 'ma-AdCard-titleLink'}, href = True)['href'],\n",
    "                'desc': soup.find('p', {'class': 'ma-AdCardDescription-text'}).text,\n",
    "                'price': price,\n",
    "                'seller': soup.find('span', {'class': 'ma-AdTag-label'}).text,\n",
    "                'mileage': mileage,\n",
    "                'year': year,\n",
    "                'transmission': transmission,\n",
    "                'doors': doors,\n",
    "                'hp': hp\n",
    "            }\n",
    "\n",
    "            # Add the dictionary to the list of vehicles\n",
    "            vehicle_list.append(vehicle)\n",
    "\n",
    "    return vehicle_list\n",
    "\n",
    "def write_csv_output(vehicle_list, output_name):\n",
    "    '''\n",
    "    Takes a list of dictionaries containing vehicle information and writes it in csv format.\n",
    "\n",
    "    Parameters:\n",
    "        vehicle_list (list):List of dictionaries containing vehicle information.\n",
    "        output_name (str): The name of the output csv file.\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    try:\n",
    "        assert isinstance(vehicle_list, list), 'The \"vehicle_list\" parameter is not a dictionary.'\n",
    "        assert isinstance(output_name, str), 'The \"output_name\" parameter is not a string.'\n",
    "    except AssertionError as ae:\n",
    "        print(ae)\n",
    "        \n",
    "    # Define a Pandas DataFrame containing the vehicle information\n",
    "    vehicle_list_df = pd.DataFrame(vehicle_list)\n",
    "    \n",
    "    # Create the output csv file with the previous data\n",
    "    vehicle_list_df.to_csv(f'{output_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1ffb2-9df4-48e5-baa8-0002be95e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_list = extract_vehicle_data(end = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c4853f-25ce-4c10-bda7-2c02b7b7933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv_output(vehicle_list, 'vehicle_listing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25735215-2c09-4c76-b89e-4e9be0394bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f2692-cde0-4a9a-9c3a-c0aba1ed1c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
